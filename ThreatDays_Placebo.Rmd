---
title: "Daily death counts prior to storm impact--Randomized dates"
output: html_document
editor_options:
  chunk_output_type: console
---

## Create an empirical storm threat model
```{r}
library(sf)
library(dplyr)

storm_intensity <- 34
begin_year <- 1985
end_year <- 2022
begin_date <- paste0(begin_year, "-01-01")
end_date <- paste0(end_year, "-12-31")

L <- "https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/shapefile/IBTrACS.NA.list.v04r00.lines.zip"
  
if(!"IBTrACS.NA.list.v04r00.lines.zip" %in% list.files(here::here("data"))) {
download.file(url = L,
              destfile = here::here("data",
                                    "IBTrACS.NA.list.v04r00.lines.zip"))
unzip(here::here("data", "IBTrACS.NA.list.v04r00.lines.zip"),
      exdir = here::here("data"))
}

Tracks.sf <- st_read(dsn = here::here("data"), 
                     layer = "IBTrACS.NA.list.v04r00.lines") |>
  st_transform(crs = 32616)

Tracks.sf <- Tracks.sf |>
  filter(year >= begin_year & year <= end_year) |>
  filter(USA_WIND >= storm_intensity) |>
  select(SID, SEASON, year, month, day, hour, min,
         NAME, SUBBASIN, ISO_TIME, USA_WIND, USA_PRES, USA_RMW, USA_EYE, USA_ROCI)

Tracks.sf |>
  st_drop_geometry() |>
  summarize(avgRMW = mean(USA_RMW, na.rm = TRUE) * 1.852,
                   avgEYE = mean(USA_EYE, na.rm = TRUE) * 1.852,
                   avgROCI = mean(USA_ROCI, na.rm = TRUE) * 1.852)

Tracks.sf <- Tracks.sf |>
  group_by(SID) |>  # pedigree
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks.sf <- Tracks.sf |>
  group_by(USA_PRES) |> # minimum pressure
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks.sf <- Tracks.sf |>
  group_by(SID) |> # pedigree
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Swaths.sf <- Tracks.sf |>
  st_buffer(dist = Tracks.sf$USA_RMW * 1852) # 1852 converts to meters

Boundaries.sf <- USAboundaries::us_states(resolution = "low", states = "FL") |> 
  st_transform(crs = 32616)

X <- Swaths.sf |>
  st_intersects(Boundaries.sf, sparse = FALSE) #Does the swath intersect the state border?
Swaths.sf <- Swaths.sf[X, ]
Swaths.sf <- Swaths.sf |>
  mutate(Date = lubridate::as_date(ISO_TIME)) #Add a date column

Swaths.sf <- Swaths.sf |>
  group_by(SID) |>
  summarize(Date0 = first(Date),
            NAME = first(NAME),
            Wind = max(USA_WIND),
            geometry = st_union(geometry)) |>
  mutate(Storm_Category = case_when(
    Wind >= 34 & Wind <= 63 ~ 0,
    Wind >= 64 & Wind <= 82 ~ 1,
    Wind >= 83 & Wind <= 95 ~ 2,
    Wind >= 96 & Wind <= 112 ~ 3,
    Wind >= 113 & Wind <= 136 ~ 4,
    Wind >= 137 ~ 5
  ))

sf_use_s2(TRUE)

Swaths.sf <- Swaths.sf |>
    st_transform(crs = 4326)
union_Swaths2.sfg <- Swaths.sf |>
  st_union()
```

## Randomized dates
```{r}
# ---- Randomize Date0 independently within the same year's season ----
library(dplyr)
library(lubridate)

season_start <- "05-01"
season_end   <- "11-30"
lead_days    <- 8
lag_days     <- 8
enforce_margin <- TRUE
set.seed(20260207)

season_bounds <- function(y, s_start = "05-01", s_end = "11-30",
                          lead = 8, lag = 8, margin = FALSE) {
  start <- as.Date(sprintf("%d-%s", y, s_start))
  end   <- as.Date(sprintf("%d-%s", y, s_end))
  if (margin) { start <- start + lead; end <- end - lag }
  if (start > end) stop(sprintf("Season window collapsed for %d.", y))
  list(start = start, end = end)
}

sample_date_uniform <- function(start, end) {
  as.Date(sample(seq(start, end, by = "day"), size = 1L))
}

min_gap_days <- 16  # keep placebo â‰¥16 days away from real Date0

draw_placebo_far <- function(y, real_d, season_start="05-01", season_end="11-30",
                             lead=8, lag=8, margin=TRUE, min_gap=16) {
  # sample until far-enough from real_d
  b <- season_bounds(y, season_start, season_end, lead, lag, margin)
  pool <- seq(b$start, b$end, by="day")
  # If pool is too small, relax margin or min_gap for that storm-year
  if (length(pool) < (2*min_gap + 7)) {
    # relax margin first
    b <- season_bounds(y, season_start, season_end, lead, lag, margin = FALSE)
    pool <- seq(b$start, b$end, by="day")
  }
  repeat {
    d <- sample(pool, 1L)
    if (abs(as.integer(d - real_d)) >= min_gap) return(as.Date(d))
  }
}

Swaths_random.sf <- Swaths.sf %>%
  mutate(Original_Date0 = Date0, Year0 = lubridate::year(Date0)) %>%
  rowwise() %>%
  mutate(Date0 = draw_placebo_far(Year0, Original_Date0,
                                  season_start, season_end,
                                  lead_days, lag_days,
                                  margin = TRUE, min_gap = min_gap_days)) %>%
  ungroup() %>%
  select(-Year0)

Swaths.sf <- Swaths_random.sf
```

## Expand `Swaths.sf` by adding rows based on the increment value of the attribute `Date0`
```{r}
library(tidyr)
library(lubridate)

min_lag  <- -8   # days before impact
max_lead <- 8   # days after impact

TIC.sf <- Swaths.sf %>% 
  rowwise() %>%
  mutate(event_days = list(
    tibble(
      Date     = Date0 + (min_lag:max_lead),
      rel_day  = min_lag:max_lead
    )
  )) %>%
  unnest(event_days) %>%
  ungroup() %>%
  select(
    Date,
    rel_day,
    Storm_Name = NAME,
    Storm_Category
  )

TIC.sf <- TIC.sf %>%
  mutate(
    rel_day_f = factor(rel_day)
  )

TIC.sf <- TIC.sf |>
  mutate(Month = lubridate::month(Date),
         Year = lubridate::year(Date))
storm_months <- unique(TIC.sf$Month)
storm_year_range <- range(TIC.sf$Year)

st_geometry(TIC.sf) <- "geom"
```

## Build a zip x date relative day calendar
~ 25 sec
```{r}
library(data.table)
library(tigris)
library(sf)
library(dplyr)

options(tigris_use_cache = TRUE)

zcta_us <- zctas(cb = TRUE, year = 2020) %>%
  select(zip = ZCTA5CE20, geometry)

fl <- states(cb = TRUE, year = 2020) %>%
  filter(STUSPS == "FL") %>%
  st_transform(st_crs(zcta_us))

zctas_fl <- st_join(zcta_us, fl, join = st_intersects, left = FALSE) %>%
  select(zip, geometry)

tic_aligned <- st_transform(TIC.sf, st_crs(zctas_fl))

tic_keep <- tic_aligned %>%
  select(Date, rel_day, geom)

zcta_date_rel_sf <- st_join(
  zctas_fl,
  tic_keep,
  join = st_intersects,
  left = FALSE
)

zcta_date_rel <- as.data.table(st_drop_geometry(zcta_date_rel_sf))
setnames(zcta_date_rel, c("zip", "Date", "rel_day"), c("zip", "date", "rel_day"))

zcta_date_rel[, `:=`(
  zip     = as.character(zip),
  date    = as.IDate(date),
  rel_day = as.integer(rel_day)
)]

zcta_date_rel <- zcta_date_rel[
  , .SD[order(abs(rel_day), rel_day)][1],
  by = .(zip, date)
]

all_zips <- sort(unique(zctas_fl$zip))
all_dates <- as.IDate(seq(as.Date(begin_date), as.Date(end_date), by = "day"))
grid <- CJ(zip = as.character(all_zips), date = all_dates)

rel_calendar <- zcta_date_rel[grid, on = .(zip, date)]

min_lag  <-  -8L
max_lead <-  8L

rel_levels <- c("None", as.character(min_lag:max_lead))

rel_calendar[, rel_day_f := fifelse(is.na(rel_day), "None", as.character(rel_day))]
rel_calendar[, rel_day_f := factor(rel_day_f, levels = rel_levels)]

# --- Sanity checks ---
stopifnot(rel_calendar[, .N, by = .(zip, date)][, all(N == 1)])
rel_calendar[, table(rel_day_f)]
```

## Merge storms with death records
~ 2 minutes
```{r}
start_time <- Sys.time()
load("data/all_data.Rdata")

Deaths.df <- all_data %>%   # Use for all deaths
  mutate(Date = as_date(DATE_OF_DEATH)) %>%
  filter(Date >= as.Date(begin_date)) %>% 
  select(Death_ID = ID, Death_Date = Date, final_lon, final_lat, 
         age = COMPUTED_AGE, white = RACE_WHITE, sex = SEX, 
         marital_code = MARITAL_CODE, army = ARMY_YESNO)

Deaths.sf <- Deaths.df %>%
  st_as_sf(coords = c("final_lon", "final_lat"), crs = 4326)
rm(all_data, Deaths.df)
Sys.time() - start_time
```

## Filter deaths by date of death and storm effect zones
~ 10 minutes
```{r}
library(sf)
library(dplyr)

start_time <- Sys.time()

target_crs <- 5070
sf_use_s2(FALSE)

min_lag  <-  -8L
max_lead <-  8L

TIC_proj    <- st_transform(TIC.sf,    target_crs)
Deaths_proj <- st_transform(Deaths.sf, target_crs)

num_obs <- nrow(Deaths_proj)
chunk_size <- 50000
num_chunks <- ceiling(num_obs / chunk_size)
print(paste("Number of chunks to process", num_chunks))

results_list <- vector("list", num_chunks)

for (i in seq(1, num_obs, by = chunk_size)) {
  chunk_index <- (i - 1) / chunk_size + 1
  chunk_indices <- i:min(i + chunk_size - 1, num_obs)

  print(paste("Processing chunk", chunk_index))

  chunk.sf <- Deaths_proj[chunk_indices, ]

  chunk_dates <- unique(chunk.sf$Death_Date)
  TIC_chunk <- TIC_proj %>% filter(Date %in% chunk_dates)

  if (nrow(TIC_chunk) == 0) {
    results_list[[chunk_index]] <- NULL
    gc()
    next
  }

  deaths_joined <- st_join(chunk.sf, TIC_chunk, join = st_within, left = FALSE) %>%
    filter(Date == Death_Date) %>%                 # enforce same-day
    mutate(rel_day = as.integer(rel_day)) %>%
    filter(rel_day >= min_lag, rel_day <= max_lead)

  if (nrow(deaths_joined) == 0) {
    results_list[[chunk_index]] <- NULL
    gc()
    next
  }

  deaths_with_impacts <- deaths_joined %>%
    group_by(Death_ID, Death_Date) %>%
    arrange(abs(rel_day), rel_day) %>%             # tie-break toward pre-impact
    slice(1) %>%
    ungroup() %>%
    transmute(
      Death_ID, Death_Date,
      Storm_Name, Storm_Category,
      rel_day,
      rel_day_f = factor(as.character(rel_day), levels = as.character(min_lag:max_lead)),
#      age, white, sex, marital_code, army, # use for all deaths
      geometry
    ) %>%
    distinct()

  results_list[[chunk_index]] <- deaths_with_impacts
  gc()
}

deaths_with_impacts <- do.call(rbind, results_list)
Sys.time() - start_time
```

## Combine with all deaths
```{r}
impacts_keep <- deaths_with_impacts %>%
  st_drop_geometry() %>%
  select(Death_ID, Death_Date, Storm_Name, Storm_Category, rel_day, rel_day_f)

deaths_all_effects <- Deaths.sf %>%
  left_join(impacts_keep, by = c("Death_ID", "Death_Date")) %>%
  mutate(
    rel_day_f = replace_na(as.character(rel_day_f), "None"),
    rel_day_f = factor(rel_day_f, levels = c("None", as.character(min_lag:max_lead))),
    rel_day   = if_else(rel_day_f == "None", NA_integer_, as.integer(rel_day))
  )
```

## Add zip codes to each death
~ 1.3 hours
```{r}
begin <- Sys.time()

target_crs <- 5070
sf_use_s2(FALSE)

zctas_fl_proj <- st_transform(zctas_fl, target_crs)
Deaths_proj <- st_transform(deaths_all_effects, target_crs)

deaths_with_zip <- st_join(
  Deaths_proj,
  zctas_fl_proj,
  join    = st_intersects,
  left    = TRUE,
  largest = TRUE
)

deaths_with_zip <- st_transform(deaths_with_zip, 4326)

# How many deaths didn't land in any ZCTA?
sum(is.na(deaths_with_zip$zip))

# Drop if desired
deaths_with_zip <- deaths_with_zip %>%
  filter(!is.na(zip))

Sys.time() - begin
```

## Panel-ready daily counts
~ 20 sec
```{r}
begin <- Sys.time()

daily_deaths <- deaths_with_zip %>%
  st_drop_geometry() %>%
  transmute(
    zip  = as.character(zip),
    date = as.IDate(Death_Date),
    age = as.integer(age)
  ) %>%
  group_by(zip, date) %>%
  summarise(deaths = n(), .groups = "drop")

library(data.table)

dat <- as.data.table(daily_deaths)
cal <- as.data.table(rel_calendar)

dat[, `:=`(zip = as.character(zip), date = as.IDate(date))]
cal[, `:=`(zip = as.character(zip), date = as.IDate(date))]

panel <- dat[cal, on = .(zip, date)]

panel[is.na(deaths), deaths := 0L]

panel[, rel_day_f := factor(as.character(rel_day_f),
                            levels = c("None", as.character(min_lag:max_lead)))]

Sys.time() - begin
```

## Poisson model with stratum fixed effects
~ 3.5 minutes
```{r}
library(fixest)
library(broom)
library(lubridate)
library(data.table)
library(dplyr)

begin <- Sys.time()

dat <- panel %>%
  filter(lubridate::month(as.Date(date)) %in% 5:11) %>%  # hurricane season only
#  filter(lubridate::year(as.Date(date)) < 2020) %>% # eliminate covid years
  transmute(
    zip       = as.character(zip),
    date      = as.IDate(date),
    deaths    = as.integer(deaths),
    rel_day_f = factor(as.character(rel_day_f),
                       levels = c("None", as.character(min_lag:max_lead))),
    dow       = factor(strftime(as.Date(date), "%u"),
                       levels = as.character(1:7),
                       labels = c("Mon","Tue","Wed","Thu","Fri","Sat","Sun")),
    ym        = factor(format(as.Date(date), "%Y-%m")),
    yw        = interaction(lubridate::year(as.Date(date)),
                            lubridate::isoweek(as.Date(date)), drop = TRUE),
    covid     = as.integer(date >= as.IDate("2020-01-01") & date <= as.IDate("2022-12-31"))
  ) %>%
  mutate(
    zip_covid = interaction(zip, covid, drop = TRUE),
    zip       = factor(zip)  # optional but helps compact FE
  )

m_event <- fepois(
  deaths ~ i(rel_day_f, ref = "None") | zip + yw + dow + zip_covid,
  data    = dat,
  cluster = ~ zip + yw,
  notes   = TRUE
)

summary(m_event)
Sys.time() - begin
```

```{r}
saveRDS(m_event, file = "m_event_34kt_placebo.rds")
```