---
title: "Modeling ER visits relative to storm effects"
output: html_document
editor_options:
  chunk_output_type: console
---

## Create a storm effects model

```{r}
library(sf)
library(dplyr)

L <- "https://www.ncei.noaa.gov/data/international-best-track-archive-for-climate-stewardship-ibtracs/v04r00/access/shapefile/IBTrACS.NA.list.v04r00.lines.zip"
  
if(!"IBTrACS.NA.list.v04r00.lines.zip" %in% list.files(here::here("data"))) {
download.file(url = L,
              destfile = here::here("data",
                                    "IBTrACS.NA.list.v04r00.lines.zip"))
unzip(here::here("data", "IBTrACS.NA.list.v04r00.lines.zip"),
      exdir = here::here("data"))
}

Tracks.sf <- st_read(dsn = here::here("data"), 
                     layer = "IBTrACS.NA.list.v04r00.lines") |>
  st_transform(crs = 32616)

Tracks.sf <- Tracks.sf |>
  filter(year >= 2004 & year <= 2022) |>
  filter(USA_WIND >= 34) |> # tropical storms and hurricanes
  select(SID, SEASON, year, month, day, hour, min,
         NAME, SUBBASIN, ISO_TIME, USA_WIND, USA_PRES, USA_RMW, USA_EYE, USA_ROCI)

Tracks.sf |>
  st_drop_geometry() |>
  summarize(avgRMW = mean(USA_RMW, na.rm = TRUE) * 1.852,
                   avgEYE = mean(USA_EYE, na.rm = TRUE) * 1.852,
                   avgROCI = mean(USA_ROCI, na.rm = TRUE) * 1.852)

# Fill in missing RMW values. Start with pedigree, then use minimum pressure, and finish again with pedigree
Tracks.sf <- Tracks.sf |>
  group_by(SID) |>  # pedigree
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks.sf <- Tracks.sf |>
  group_by(USA_PRES) |> # minimum pressure
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

Tracks.sf <- Tracks.sf |>
  group_by(SID) |> # pedigree
  mutate(USA_RMW = ifelse(is.na(USA_RMW), mean(USA_RMW, na.rm = TRUE), USA_RMW))

#Add a buffer to the tracks to make segmented wind swaths
Swaths.sf <- Tracks.sf |>
  st_buffer(dist = Tracks.sf$USA_RMW * 1852) # 1852 converts to meters

# Wind swaths that cross Florida. `USAboundaries` package no longer maintained on CRAN
#devtools::install_github("ropensci/USAboundariesData")
#devtools::install_github("ropensci/USAboundaries", force = TRUE)
#install.packages("USAboundariesData", repos = "https://ropensci.r-universe.dev", type = "source")
Boundaries.sf <- USAboundaries::us_states(resolution = "low", states = "FL") |> 
  st_transform(crs = 32616)

X <- Swaths.sf |>
  st_intersects(Boundaries.sf, sparse = FALSE) #Does the swath intersect the state border?
Swaths.sf <- Swaths.sf[X, ]
Swaths.sf <- Swaths.sf |>
  mutate(Date = lubridate::as_date(ISO_TIME)) #Add a date column

# Extract the boundaries of storm impacts by storm ID. Dissolve the overlap borders of the individual swaths by storm to create a single storm swath. Add the storm category (Saffir-Simpson) based on wind speed
Swaths.sf <- Swaths.sf |>
  group_by(SID) |>
  summarize(Date0 = first(Date),
            NAME = first(NAME),
            Wind = max(USA_WIND),
            geometry = st_union(geometry)) |>
  mutate(Storm_Category = case_when(
    Wind >= 34 & Wind <= 63 ~ 0,
    Wind >= 64 & Wind <= 82 ~ 1,
    Wind >= 83 & Wind <= 95 ~ 2,
    Wind >= 96 & Wind <= 112 ~ 3,
    Wind >= 113 & Wind <= 136 ~ 4,
    Wind >= 137 ~ 5
  ))

# Transform the geometry to a geographic CRS (4326) and unionize the swaths
sf_use_s2(TRUE)

Swaths.sf <- Swaths.sf |>
    st_transform(crs = 4326)
union_Swaths2.sfg <- Swaths.sf |>
  st_union()
```

Expand `Swaths.sf` by adding rows based on the increment value of the attribute `Date0`. Dates prior to the impact date are threat dates and those after the impact date are cleanup dates. Here we used one day prior and one day after impact
```{r}
library(tidyr)

deltaT <- 1   # One day increment
n_new <- 14    # Number of new rows to create for each feature (row) times 2

TIC.sf <- Swaths.sf |>
    rowwise() |>
    mutate(new_features = list(tidyr::tibble(
           Date = Date0 + (-n_new:n_new) * deltaT))) |>
    unnest(new_features) |>
    ungroup() |>
    select(Date, Storm_Name = NAME, Storm_Category)

TIC <- rep(rep(c("Threat", "Impact", "Cleanup"), times = c(n_new, 1, n_new)), 
           times = nrow(Swaths.sf))
TIC.sf$Storm_Effect <- TIC

# Add month and year indicators change name of the geometry column (this is needed for spatial merges)
TIC.sf <- TIC.sf |>
  mutate(Month = month(Date),
         Year = year(Date))
storm_months <- unique(TIC.sf$Month)
storm_year_range <- range(TIC.sf$Year)

st_geometry(TIC.sf) <- "geom"
```

## Build a zip x date effect calendar

```{r}
library(tigris)
options(tigris_use_cache = TRUE)

# Florida zips
zctas_fl <- zctas(cb = FALSE, year = 2010, state = "FL") %>%
  select(zip = ZCTA5CE10, geometry)

#Align coordinate reference systems
tic_aligned  <- st_transform(TIC.sf,  st_crs(zctas_fl))

# Spatial join: which zips intersect each TIC polygon (by date & effect)
# Keep only the columns we need from TIC
tic_keep <- tic_aligned |> 
  select(Date, Storm_Effect, geom)

# Point-in-polygon for polygons
zcta_date_effect_sf <- st_join(
  zctas_fl,
  tic_keep,
  join = st_intersects,
  left = FALSE   # keep only zips that intersect a TIC polygon on that date
)

# Drop geometry for the calendar
zcta_date_effect <- as.data.table(st_drop_geometry(zcta_date_effect_sf))
setnames(zcta_date_effect, c("zip","Date","Storm_Effect"),
         c("zip","date","effect"))

# Normalize types
zcta_date_effect[, `:=`(
  zip    = as.character(zip),
  date   = as.IDate(date),
  effect = as.character(effect)
)]

# Resolve multiple effects on the same zip-date: Choose most severe ranking (None < Cleanup < Threat < Impact)
sev <- data.table(effect = c("None","Cleanup","Threat","Impact"),
                  rank   = 0:3)
zde <- sev[zcta_date_effect, on = "effect"]

# Keep the single most-severe label per ZIP–date
zde <- zde[ , .SD[which.max(rank)], by = .(zip, date)][ , .(zip, date, effect)]

# Build the full zip x date data frame & fill missing days with "None"
all_zips  <- sort(unique(zde$zip))
all_dates <- as.IDate(seq(as.Date("2004-12-31"), as.Date("2022-12-31"), by = "day"))
grid <- CJ(zip = as.character(all_zips), date = all_dates)

# Left-join the observed effects; fill NA → "None"
effect_calendar <- zde[grid, on = .(zip, date)]
effect_calendar[is.na(effect), effect := "None"]

# Keep effect as a factor with ordered levels
effect_calendar[, effect := factor(effect, levels = c("None","Cleanup","Threat","Impact"))]

# Exactly one effect per ZIP–day?
stopifnot(effect_calendar[, .N, by = .(zip, date)][, all(N == 1)])

# Effects present?
effect_calendar[, table(effect)]
```

## Merge with emergency room visits

Data received from David Hsu on October 16, 2025 via email
```{r}
ER_visits.dt <- data.table::fread(here::here("data", "Combined_ER_Data.csv"))
ER_visits.df <- ER_visits.dt |>
  as.data.frame()
```

Clean the data
```{r}
library(data.table)

setDT(ER_visits.df)

# Pad ZipCode to 5 chars; drop non-sensical codes (0/NA/too short/too big)
ER_visits.df[
  , ZipCode := fifelse(ZipCode > 0 & ZipCode < 1e6, sprintf("%05d", ZipCode), NA_character_)
]
ER_visits.df[, Date := as.IDate(Date)]

ER_visits_clean <- ER_visits.df[!is.na(ZipCode) & nchar(ZipCode) == 5]

# Standardize names; optionally collapse duplicates
setnames(ER_visits_clean, c("ZipCode","Date","Total_Visits"),
                           c("zip",    "date","er_visits"))

# If there can be multiple ER rows per (zip,date), aggregate to daily total
ER_visits_clean <- ER_visits_clean[, .(er_visits = sum(er_visits, na.rm = TRUE)),
                                   by = .(zip, date)]

merged <- merge(
  effect_calendar,
  ER_visits_clean,
  by = c("zip", "date"),
  all.x = TRUE  # keep all ZIP–dates from the calendar
)

merged[is.na(er_visits), er_visits := 0L]

library(lubridate)   # for yearmonth(), wday()
setDT(merged)

# Add day of week (factor, ordered Monday–Sunday)
merged[, dow := lubridate::wday(date, label = TRUE, abbr = TRUE)]

# Add year-month (IDate stored as "YYYY-MM-01" for convenience)
merged[, year_month := as.IDate(floor_date(date, unit = "month"))]

```

## Model using logit and Poisson separately

Instead use a two-part “threshold (≤6) + truncated count (>6)” approximation (stays in `fixest`). The process is modeled as:
Part A (logit): probability the true count is ≤6 (we observe 6)
Part B (Poisson on truncated support): conditional mean for counts >6
Then combine for interpretation

```{r}
library(fixest)
library(dplyr)

d2 <- merged %>% mutate(
  is_le6 = as.integer(er_visits == 6L)           # proxy for "true ≤ 6"
)

# Part A: logistic model for being ≤ 6
mA <- feglm(
  is_le6 ~ i(effect, ref="None") | zip + year_month + dow,
  data = d2, family = binomial("logit"),
  cluster = ~ zip + year_month
)

# Part B: Poisson on Y>6 (treat observed counts >6 as exact)
d_gt6 <- filter(d2, er_visits > 6L)
mB <- fepois(
  er_visits ~ i(effect, ref="None") | zip + year_month + dow,
  data = d_gt6, cluster = ~ zip + year_month
)

summary(mA); summary(mB)
```

Binomial model:
Cleanup and Threat days: No meaningful evidence that these periods change the probability of low ER visits.
Impact days (landfall): A positive and significant log-odds means ER visit counts are more likely to fall in the ≤6 range. In other words, ER utilization tends to drop during direct storm impact

This makes sense: Many people stay home. Clinics/hospitals reduce service hours. Travel becomes difficult.
This model focuses on the lower tail of demand — and here, Impact days show a clear reduction

Poisson model:
Cleanup days: No real change in ER volume. Threat days (pre-impact conditions): ER visits increase slightly (+1–2%). People may seek care before the storm hits (filling prescriptions, addressing minor issues early).
Impact days: ER visits drop sharply (≈ –8%). This lines up perfectly with the binomial model’s finding: ER demand suppresses during the storm’s immediate impact

Jointly the models show storm Impact periods suppress ER utilization — likely due to mobility constraints, closures, and shelter-in-place behavior. Pre-storm Threat periods slightly elevate ER visits, consistent with precautionary care. Cleanup periods show little to no deviation, perhaps because they mix delayed care (upward) with infrastructure disruptions (downward). This is exactly the kind of pattern you’d expect in a population with both anticipatory behavior and acute disruption around major storms

* Compare results with a subset of the stronger storms 55+
* Use longer and shorter times (number of days) before (Threat) and after (Cleanup)
